{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgZlrHPcWVCL",
        "outputId": "20e29dc7-52d6-4959-ad57-996336907a68"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1GihE0Z-ClH",
        "outputId": "c7db1d65-027d-4d61-ed87-f4177098d0e1"
      },
      "outputs": [],
      "source": [
        "import wikipedia\n",
        "import pandas as pd\n",
        "!pip install wikipedia\n",
        "articles = ['Grocery', 'Fruits', 'Vegetables',\n",
        "            'Clothing', 'Cloth', 'Dress', 'Clothes', 'Garment']\n",
        "wiki_lst = []\n",
        "title = []\n",
        "for article in articles:\n",
        "    print(\"loading content: \", article)\n",
        "    wiki_lst.append(wikipedia.page(article).content)\n",
        "    title.append(article)\n",
        "print(\"examine content\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQhg2yCp-HP9"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words={'english'})\n",
        "X = vectorizer.fit_transform(wiki_lst)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "ZxBz6vOt-MzI",
        "outputId": "2118883e-fb7c-4e72-8841-24d9e82e8cb3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "Sum_of_squared_distances = []\n",
        "K = range(1, 7)\n",
        "for k in K:\n",
        "    km = KMeans(n_clusters=k, max_iter=200, n_init=10)\n",
        "    km = km.fit(X)\n",
        "    Sum_of_squared_distances.append(km.inertia_)\n",
        "plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Sum_of_squared_distances')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6hWo032_oWb",
        "outputId": "2e87ae6c-13bf-46e0-8318-fedac0d72742"
      },
      "outputs": [],
      "source": [
        "true_k = 2\n",
        "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=2000, n_init=10)\n",
        "model.fit(X)\n",
        "labels = model.labels_\n",
        "wiki_cl = pd.DataFrame(list(zip(title, labels)), columns=['title', 'cluster'])\n",
        "print(wiki_cl.sort_values(by=['cluster']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "3SLyjRu6_0Ru",
        "outputId": "8d4e6a58-7ddb-4f57-9e6b-a1a815ed384c"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "result = {'cluster': labels, 'wiki': wiki_lst}\n",
        "result = pd.DataFrame(result)\n",
        "for k in range(0, true_k):\n",
        "    s = result[result.cluster == k]\n",
        "    text = s['wiki'].str.cat(sep=' ')\n",
        "    text = text.lower()\n",
        "    text = ' '.join([word for word in text.split()])\n",
        "    wordcloud = WordCloud(max_font_size=50, max_words=100,\n",
        "                          background_color=\"white\").generate(text)\n",
        "    print('Cluster: {}'.format(k))\n",
        "   #  print('Titles')\n",
        "    titles = wiki_cl[wiki_cl.cluster == k]['title']\n",
        "    # print(titles.to_string(index=False))\n",
        "    plt.figure()\n",
        "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SKuLItPAiVa"
      },
      "outputs": [],
      "source": [
        "\n",
        "with open('/content/drive/MyDrive/0_IDE_Presentation/TestData.txt', 'r') as file:\n",
        "    data = file.read().replace('\\n', '')\n",
        "array = [1]\n",
        "array[0] = data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6apbbKiCPJ8",
        "outputId": "4232d672-3e57-4b6d-d764-1de4aa5302e1"
      },
      "outputs": [],
      "source": [
        "Test = vectorizer.transform(array)\n",
        "b = model.predict(Test)\n",
        "print(b)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Clustering.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "91298d0f9180f10e73e9f53de043ff9b670ae1f4be5a9b3debada2a5a30e3a0e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
